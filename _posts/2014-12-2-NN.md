---
layout: post
title: "Digit Recognizer by Neural Network"
categories: [R]
tags: [neural network, machine learning, kaggle]

---

### Intorduction    
This algorithm is for a [kaggle competition](https://www.kaggle.com/c/digit-recognizer) to take an image of a handwritten single digit, and determine what that digit is. The data used is [MNIST data](https://www.kaggle.com/c/digit-recognizer/data).     

The trainning data include 42000 image of hand-drawn digits. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.  

Here is the data for handwritten 1:

{% highlight r %}
sample_data <- read.csv("train.csv", header=TRUE,nrows=10)
matrix(sample_data[1,-1],28,28)
{% endhighlight %}



{% highlight text %}
##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
##  [1,] 0    0    0    0    0    0    0    0    0    0     0     0    
##  [2,] 0    0    0    0    0    0    0    0    0    0     0     0    
##  [3,] 0    0    0    0    0    0    0    0    0    0     0     0    
##  [4,] 0    0    0    0    0    0    0    0    0    0     0     0    
##  [5,] 0    0    0    0    0    0    0    0    0    0     0     0    
##  [6,] 0    0    0    0    0    0    0    0    0    0     0     0    
##  [7,] 0    0    0    0    0    0    0    0    0    0     0     0    
##  [8,] 0    0    0    0    0    0    0    0    0    0     0     0    
##  [9,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [10,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [11,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [12,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [13,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [14,] 0    0    0    0    0    0    0    0    0    0     0     23   
## [15,] 0    0    0    0    0    0    0    0    0    0     93    210  
## [16,] 0    0    0    0    0    0    0    0    0    54    254   254  
## [17,] 0    0    0    0    0    0    0    0    29   209   253   253  
## [18,] 0    0    0    0    0    0    0    80   207  253   238   159  
## [19,] 0    0    0    0    0    0    123  247  253  253   170   0    
## [20,] 0    0    0    0    0    191  248  253  235  88    17    0    
## [21,] 0    0    0    0    188  250  253  208  77   0     0     0    
## [22,] 0    0    0    0    255  253  167  13   0    0     0     0    
## [23,] 0    0    0    0    94   93   10   0    0    0     0     0    
## [24,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [25,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [26,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [27,] 0    0    0    0    0    0    0    0    0    0     0     0    
## [28,] 0    0    0    0    0    0    0    0    0    0     0     0    
##       [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]
##  [1,] 0     0     0     0     0     0     0     0     0     0    
##  [2,] 0     0     0     0     0     0     0     0     0     0    
##  [3,] 0     0     0     0     0     0     0     0     0     0    
##  [4,] 0     0     0     0     0     0     0     0     0     0    
##  [5,] 0     0     0     0     0     0     0     0     0     0    
##  [6,] 0     0     0     0     0     0     0     0     0     0    
##  [7,] 0     0     0     0     0     0     0     0     0     0    
##  [8,] 0     0     0     0     0     0     0     0     15    94   
##  [9,] 0     0     0     0     0     0     0     89    220   253  
## [10,] 0     0     0     0     0     22    103   240   253   253  
## [11,] 0     0     0     0     20    188   253   253   253   253  
## [12,] 0     0     20    168   203   253   253   195   80    94   
## [13,] 16    27    206   253   253   245   191   25    0     0    
## [14,] 209   253   254   253   248   93    0     0     0     0    
## [15,] 253   253   254   196   76    0     0     0     0     0    
## [16,] 254   254   198   7     0     0     0     0     0     0    
## [17,] 240   13    7     0     0     0     0     0     0     0    
## [18,] 81    0     0     0     0     0     0     0     0     0    
## [19,] 0     0     0     0     0     0     0     0     0     0    
## [20,] 0     0     0     0     0     0     0     0     0     0    
## [21,] 0     0     0     0     0     0     0     0     0     0    
## [22,] 0     0     0     0     0     0     0     0     0     0    
## [23,] 0     0     0     0     0     0     0     0     0     0    
## [24,] 0     0     0     0     0     0     0     0     0     0    
## [25,] 0     0     0     0     0     0     0     0     0     0    
## [26,] 0     0     0     0     0     0     0     0     0     0    
## [27,] 0     0     0     0     0     0     0     0     0     0    
## [28,] 0     0     0     0     0     0     0     0     0     0    
##       [,23] [,24] [,25] [,26] [,27] [,28]
##  [1,] 0     0     0     0     0     0    
##  [2,] 0     0     0     0     0     0    
##  [3,] 0     0     0     0     0     0    
##  [4,] 0     0     0     0     0     0    
##  [5,] 0     0     0     0     0     0    
##  [6,] 0     0     0     0     0     0    
##  [7,] 0     0     0     0     0     0    
##  [8,] 89    0     0     0     0     0    
##  [9,] 251   214   0     0     0     0    
## [10,] 253   218   0     0     0     0    
## [11,] 250   95    0     0     0     0    
## [12,] 131   0     0     0     0     0    
## [13,] 0     0     0     0     0     0    
## [14,] 0     0     0     0     0     0    
## [15,] 0     0     0     0     0     0    
## [16,] 0     0     0     0     0     0    
## [17,] 0     0     0     0     0     0    
## [18,] 0     0     0     0     0     0    
## [19,] 0     0     0     0     0     0    
## [20,] 0     0     0     0     0     0    
## [21,] 0     0     0     0     0     0    
## [22,] 0     0     0     0     0     0    
## [23,] 0     0     0     0     0     0    
## [24,] 0     0     0     0     0     0    
## [25,] 0     0     0     0     0     0    
## [26,] 0     0     0     0     0     0    
## [27,] 0     0     0     0     0     0    
## [28,] 0     0     0     0     0     0
{% endhighlight %}





Let's visualize some sample data:     

{% highlight r %}
require(graphics)

flip = function(x) {
  xx=matrix(0,nrow(x),ncol(x))
  for (i in (1:nrow(x))){
    xx[i,] = rev(x[i,])}
  return(xx)}

sample_plot = function(x,n) {
  xx = list()
  par(mfrow=c(sqrt(n), sqrt(n)),mar=rep(0.2,4))
  for (i in 1:n) {
    temp = as.numeric(x[i,])
    temp = matrix(temp,28,28)
    xx[[i]] = flip(temp)
    image(z=xx[[i]], col=gray.colors(12),xaxt='n',yaxt='n',ann=FALSE)
  }}

sample_p <- read.csv("train.csv", header=TRUE,nrows=100)
sample_p = sample_p[,-1]
sample_plot(sample_p,64)
{% endhighlight %}

![plot of chunk unnamed-chunk-2](/figure/source/2014-12-2-NN/unnamed-chunk-2-1.png) 




### Neural Network Algorithm  


The General Neural Newwork model shows below:

$$
z^{(l+1)} = a^{(l)}(\Theta^{(l)})^T 
$$

$$
a^{(l+1)} = f_{\theta}(z^{(l+1)}) 
$$

Here is structure of one hidden layer  Neural Network(with 15 unit in the hidden layer):
![NN graph][101]



For classification problem, we use Cross-entropy cost function:    

$$
J(\Theta)= -\frac{1}{m}  \left[  \sum^m_i \sum^K_k y^{(i)}_{k}log f_\theta (z^{(i)})_{k}  
  + (1-y^{(i)}_k ) log( 1- f_\theta (z^{(i)})_{k} )  \right]     
$$

or the simple version:

$$
J(\Theta)= -\frac{1}{m} \sum^m_i \sum^K_k y^{(i)}_{k}log f_\theta (z^{(i)})_{k}      
$$


From the cost function $J(\Theta)$, we have derivatives:

$$
\frac{\partial J(\Theta)}{\partial \Theta^{(l)}} =  \frac{f_{\theta}(z^{(l+1)})}{\partial z^{(l+1)}} \frac{\partial z^{(l+1)}}{\partial \Theta^{(l)}}
$$

$$
\frac{\partial J(\Theta)}{\partial \Theta^{(l)}} =  (y-f_{\theta}(z^{(l+1)}))^Ta^{l}
$$


Here is the R code for the neural network. This model include two hidden layers with 25 units in first hidden layer 16 units in second hidden layer. I  minimize $J(\Theta)$ by gradient descent, called back-propagation in the setting.    



{% highlight r %}
  a1 = cbind(1,data)
  z2 = a1%*%t(Theta1)
  a2 = cbind(1,sigmoid(z2)) #add the bias term
  z3 = a2%*%t(Theta2)
  a3 = cbind(1,sigmoid(z3)) #add the bias term
  z4 = a3%*%t(Theta3)
  h = sigmoid(z4)
  # reshape the y
  ny = matrix(0, length(y),num_labels)
  for (i in 1:length(y)){
    ny[i,y[i]] = 1}
  
  # cost function
  regu = lambda*(sum(Theta1[,-1]^2) + sum(Theta2[,-1]^2) + sum(Theta3[,-1]^2))/(2*m)
  cost = -sum(ny*log(h)+(1-ny)*log(1-h))/m+regu

  # back propagation
  delta4 = h-ny
  delta3 = (delta4%*%Theta3[,-1])*sigmoidGradient(z3)
  delta2 = (delta3%*%Theta2[,-1])*sigmoidGradient(z2)
  # add the bias term
  thres1 = matrix(1,nrow(Theta1),ncol(Theta1))
  thres1[,1] = 0
  thres2 = matrix(1,nrow(Theta2),ncol(Theta2))
  thres2[,1] = 0
  thres3 = matrix(1,nrow(Theta3),ncol(Theta3))
  Theta1_grad = (t(delta2)%*%a1)/m + thres1*Theta1*lambda/m
  Theta2_grad = (t(delta3)%*%a2)/m + thres2*Theta2*lambda/m
  Theta3_grad = (t(delta4)%*%a3)/m + thres3*Theta3*lambda/m
{% endhighlight %}










[101]:tikz12.png "NN"
